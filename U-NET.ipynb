{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shunsuketama/Shintama/blob/main/U-NET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5KrEb6vrkR"
      },
      "source": [
        "# Colab へようこそ"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kkiDWletiZqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "k-F6gIzkk6dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh7cF_x0lCKy",
        "outputId": "b8fbb491-db7c-4f25-9a5b-f6cede3cd2af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "print(cv2.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HzMoBAtlIg_",
        "outputId": "c328d2ba-7062-4fd0-bd02-21b58f1a67ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YOxvWkzOlqh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "metadata": {
        "id": "xEW-nihW1hls",
        "outputId": "c01805a5-249c-4a0a-da57-784146aad861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "DIR = Path(\"/content/drive/MyDrive/nv_detection_project/raw_data/annotated\")\n",
        "\n",
        "for p in DIR.iterdir():\n",
        "    if not p.is_file():\n",
        "        continue\n",
        "\n",
        "    # 例: 1-10385045L.tif\n",
        "    name = p.stem      # \"1-10385045L\"\n",
        "    ext  = p.suffix    # \".tif\"\n",
        "\n",
        "    if \"-\" not in name:\n",
        "        print(\"スキップ（'-'なし）:\", p.name)\n",
        "        continue\n",
        "\n",
        "    left, right = name.split(\"-\", 1)\n",
        "    new_name = f\"{right}-{left}{ext}\"\n",
        "\n",
        "    new_path = p.with_name(new_name)\n",
        "\n",
        "    print(f\"{p.name}  →  {new_name}\")\n",
        "    p.rename(new_path)\n",
        "\n",
        "print(\"リネーム完了\")\n"
      ],
      "metadata": {
        "id": "imBy_CZ61jnW",
        "outputId": "c51d69b8-db16-4dde-8b0d-15c3a47053e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-10794878.jpg  →  10794878-2.jpg\n",
            "8-10385045R.tif  →  10385045R-8.tif\n",
            "9-10385045R.tif  →  10385045R-9.tif\n",
            "20-10385045R.tif  →  10385045R-20.tif\n",
            "19-10385045R.tif  →  10385045R-19.tif\n",
            "17-10385045R.tif  →  10385045R-17.tif\n",
            "13-10385045R.tif  →  10385045R-13.tif\n",
            "1-10385045R.tif  →  10385045R-1.tif\n",
            "5-10385045R.tif  →  10385045R-5.tif\n",
            "2-10385045R.tif  →  10385045R-2.tif\n",
            "6-10385045R.tif  →  10385045R-6.tif\n",
            "14-10385045R.tif  →  10385045R-14.tif\n",
            "10-10385045R.tif  →  10385045R-10.tif\n",
            "12-10385045L.tif  →  10385045L-12.tif\n",
            "15-10385045L.tif  →  10385045L-15.tif\n",
            "16-10385045L.tif  →  10385045L-16.tif\n",
            "4-10385045L.tif  →  10385045L-4.tif\n",
            "7-10385045R.tif  →  10385045R-7.tif\n",
            "3-10385045R.tif  →  10385045R-3.tif\n",
            "11-10385045R.tif  →  10385045R-11.tif\n",
            "15-10385045R.tif  →  10385045R-15.tif\n",
            "12-10385045R.tif  →  10385045R-12.tif\n",
            "16-10385045R.tif  →  10385045R-16.tif\n",
            "4-10385045R.tif  →  10385045R-4.tif\n",
            "18-10385045R.tif  →  10385045R-18.tif\n",
            "19-10385045L.tif  →  10385045L-19.tif\n",
            "18-10385045L.tif  →  10385045L-18.tif\n",
            "9-10385045L.tif  →  10385045L-9.tif\n",
            "7-10385045L.tif  →  10385045L-7.tif\n",
            "3-10385045L.tif  →  10385045L-3.tif\n",
            "11-10385045L.tif  →  10385045L-11.tif\n",
            "6-10385045L.tif  →  10385045L-6.tif\n",
            "2-10385045L.tif  →  10385045L-2.tif\n",
            "14-10385045L.tif  →  10385045L-14.tif\n",
            "10-10385045L.tif  →  10385045L-10.tif\n",
            "20-10385045L.tif  →  10385045L-20.tif\n",
            "8-10385045L.tif  →  10385045L-8.tif\n",
            "17-10385045L.tif  →  10385045L-17.tif\n",
            "13-10385045L.tif  →  10385045L-13.tif\n",
            "1-10385045L.tif  →  10385045L-1.tif\n",
            "5-10385045L.tif  →  10385045L-5.tif\n",
            "39-11846715.jpg  →  11846715-39.jpg\n",
            "48-11846715.jpg  →  11846715-48.jpg\n",
            "32-11846715.jpg  →  11846715-32.jpg\n",
            "27-11846715.jpg  →  11846715-27.jpg\n",
            "20-11846715.jpg  →  11846715-20.jpg\n",
            "8-11846715.jpg  →  11846715-8.jpg\n",
            "38-11846715.jpg  →  11846715-38.jpg\n",
            "49-11846715.jpg  →  11846715-49.jpg\n",
            "9-11846715.jpg  →  11846715-9.jpg\n",
            "51-11846715.jpg  →  11846715-51.jpg\n",
            "5-11846715.jpg  →  11846715-5.jpg\n",
            "2-11846715.jpg  →  11846715-2.jpg\n",
            "35-11846715.jpg  →  11846715-35.jpg\n",
            "34-11846715.jpg  →  11846715-34.jpg\n",
            "16-11846715.jpg  →  11846715-16.jpg\n",
            "43-11846715.jpg  →  11846715-43.jpg\n",
            "11-11846715.jpg  →  11846715-11.jpg\n",
            "44-11846715.jpg  →  11846715-44.jpg\n",
            "10-11846715.jpg  →  11846715-10.jpg\n",
            "42-11846715.jpg  →  11846715-42.jpg\n",
            "17-11846715.jpg  →  11846715-17.jpg\n",
            "21-11846715.jpg  →  11846715-21.jpg\n",
            "26-11846715.jpg  →  11846715-26.jpg\n",
            "3-11846715.jpg  →  11846715-3.jpg\n",
            "4-11846715.jpg  →  11846715-4.jpg\n",
            "33-11846715.jpg  →  11846715-33.jpg\n",
            "12-11846715.jpg  →  11846715-12.jpg\n",
            "47-11846715.jpg  →  11846715-47.jpg\n",
            "36-11846715.jpg  →  11846715-36.jpg\n",
            "31-11846715.jpg  →  11846715-31.jpg\n",
            "6-11846715.jpg  →  11846715-6.jpg\n",
            "1-11846715.jpg  →  11846715-1.jpg\n",
            "50-11846715.jpg  →  11846715-50.jpg\n",
            "45-11846715.jpg  →  11846715-45.jpg\n",
            "41-11846715.jpg  →  11846715-41.jpg\n",
            "14-11846715.jpg  →  11846715-14.jpg\n",
            "30-11846715.jpg  →  11846715-30.jpg\n",
            "37-11846715.jpg  →  11846715-37.jpg\n",
            "7-11846715.jpg  →  11846715-7.jpg\n",
            "22-11846715.jpg  →  11846715-22.jpg\n",
            "25-11846715.jpg  →  11846715-25.jpg\n",
            "52-11846715.jpg  →  11846715-52.jpg\n",
            "15-11846715.jpg  →  11846715-15.jpg\n",
            "40-11846715.jpg  →  11846715-40.jpg\n",
            "29-11846715.jpg  →  11846715-29.jpg\n",
            "18-11846715.jpg  →  11846715-18.jpg\n",
            "28-11846715.jpg  →  11846715-28.jpg\n",
            "19-11846715.jpg  →  11846715-19.jpg\n",
            "46-11846715.jpg  →  11846715-46.jpg\n",
            "13-11846715.jpg  →  11846715-13.jpg\n",
            "8-10794878.tif  →  10794878-8.tif\n",
            "11-10794878.tif  →  10794878-11.tif\n",
            "9-10794878.tif  →  10794878-9.tif\n",
            "21-10794878.tif  →  10794878-21.tif\n",
            "10-10794878.tif  →  10794878-10.tif\n",
            "17-10794878.tif  →  10794878-17.tif\n",
            "20-10794878.tif  →  10794878-20.tif\n",
            "5-10794878.tif  →  10794878-5.tif\n",
            "16-10794878.tif  →  10794878-16.tif\n",
            "14-10794878.tif  →  10794878-14.tif\n",
            "6-10794878.tif  →  10794878-6.tif\n",
            "1-10794878.tif  →  10794878-1.tif\n",
            "15-10794878.tif  →  10794878-15.tif\n",
            "12-10794878.tif  →  10794878-12.tif\n",
            "3-10794878.tif  →  10794878-3.tif\n",
            "4-10794878.tif  →  10794878-4.tif\n",
            "14-1139339.jpg  →  1139339-14.jpg\n",
            "9-1139339.jpg  →  1139339-9.jpg\n",
            "19-10794878.tif  →  10794878-19.tif\n",
            "33-1139339.jpg  →  1139339-33.jpg\n",
            "18-10794878.tif  →  10794878-18.tif\n",
            "7-10794878.tif  →  10794878-7.tif\n",
            "13-10794878.tif  →  10794878-13.tif\n",
            "18-1139339.jpg  →  1139339-18.jpg\n",
            "29-1139339.jpg  →  1139339-29.jpg\n",
            "23-1139339.jpg  →  1139339-23.jpg\n",
            "5-1139339.jpg  →  1139339-5.jpg\n",
            "11-1139339.jpg  →  1139339-11.jpg\n",
            "26-1139339.jpg  →  1139339-26.jpg\n",
            "3-1139339.jpg  →  1139339-3.jpg\n",
            "25-1139339.jpg  →  1139339-25.jpg\n",
            "12-1139339.jpg  →  1139339-12.jpg\n",
            "6-1139339.jpg  →  1139339-6.jpg\n",
            "20-1139339.jpg  →  1139339-20.jpg\n",
            "10-1139339.jpg  →  1139339-10.jpg\n",
            "1-1139339.jpg  →  1139339-1.jpg\n",
            "4-1139339.jpg  →  1139339-4.jpg\n",
            "22-1139339.jpg  →  1139339-22.jpg\n",
            "19-1139339.jpg  →  1139339-19.jpg\n",
            "30-1139339.jpg  →  1139339-30.jpg\n",
            "17-1139339.jpg  →  1139339-17.jpg\n",
            "31-1139339.jpg  →  1139339-31.jpg\n",
            "16-1139339.jpg  →  1139339-16.jpg\n",
            "32-1139339.jpg  →  1139339-32.jpg\n",
            "8-1139339.jpg  →  1139339-8.jpg\n",
            "15-1139339.jpg  →  1139339-15.jpg\n",
            "27-1139339.jpg  →  1139339-27.jpg\n",
            "28-1139339.jpg  →  1139339-28.jpg\n",
            "34-1139339.jpg  →  1139339-34.jpg\n",
            "7-1139339.jpg  →  1139339-7.jpg\n",
            "21-1139339.jpg  →  1139339-21.jpg\n",
            "13-1139339.jpg  →  1139339-13.jpg\n",
            "2-1139339.jpg  →  1139339-2.jpg\n",
            "24-1139339.jpg  →  1139339-24.jpg\n",
            "リネーム完了\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "metadata": {
        "id": "hoXdRPsP_z1m",
        "outputId": "7f4173a1-d626-433e-dee1-f3ede730f17c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "DIR = Path(\"/content/drive/MyDrive/nv_detection_project/raw_data/original\")\n",
        "\n",
        "for p in DIR.iterdir():\n",
        "    if not p.is_file():\n",
        "        continue\n",
        "\n",
        "    # 例: 1-10385045L.tif\n",
        "    name = p.stem      # \"1-10385045L\"\n",
        "    ext  = p.suffix    # \".tif\"\n",
        "\n",
        "    if \"-\" not in name:\n",
        "        print(\"スキップ（'-'なし）:\", p.name)\n",
        "        continue\n",
        "\n",
        "    left, right = name.split(\"-\", 1)\n",
        "    new_name = f\"{right}-{left}{ext}\"\n",
        "\n",
        "    new_path = p.with_name(new_name)\n",
        "\n",
        "    print(f\"{p.name}  →  {new_name}\")\n",
        "    p.rename(new_path)\n",
        "\n",
        "print(\"リネーム完了\")\n"
      ],
      "metadata": {
        "id": "saCCYha7ADil",
        "outputId": "e733ce98-9270-40e3-e0c0-bb3b6485298b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-11846715.jpg  →  11846715-1.jpg\n",
            "2-11846715.jpg  →  11846715-2.jpg\n",
            "3-11846715.jpg  →  11846715-3.jpg\n",
            "4-11846715.jpg  →  11846715-4.jpg\n",
            "5-11846715.jpg  →  11846715-5.jpg\n",
            "6-11846715.jpg  →  11846715-6.jpg\n",
            "7-11846715.jpg  →  11846715-7.jpg\n",
            "8-11846715.jpg  →  11846715-8.jpg\n",
            "9-11846715.jpg  →  11846715-9.jpg\n",
            "10-11846715.jpg  →  11846715-10.jpg\n",
            "11-11846715.jpg  →  11846715-11.jpg\n",
            "12-11846715.jpg  →  11846715-12.jpg\n",
            "13-11846715.jpg  →  11846715-13.jpg\n",
            "14-11846715.jpg  →  11846715-14.jpg\n",
            "15-11846715.jpg  →  11846715-15.jpg\n",
            "16-11846715.jpg  →  11846715-16.jpg\n",
            "17-11846715.jpg  →  11846715-17.jpg\n",
            "18-11846715.jpg  →  11846715-18.jpg\n",
            "19-11846715.jpg  →  11846715-19.jpg\n",
            "20-11846715.jpg  →  11846715-20.jpg\n",
            "21-11846715.jpg  →  11846715-21.jpg\n",
            "22-11846715.jpg  →  11846715-22.jpg\n",
            "32-11846715.jpg  →  11846715-32.jpg\n",
            "33-11846715.jpg  →  11846715-33.jpg\n",
            "34-11846715.jpg  →  11846715-34.jpg\n",
            "35-11846715.jpg  →  11846715-35.jpg\n",
            "36-11846715.jpg  →  11846715-36.jpg\n",
            "37-11846715.jpg  →  11846715-37.jpg\n",
            "38-11846715.jpg  →  11846715-38.jpg\n",
            "39-11846715.jpg  →  11846715-39.jpg\n",
            "40-11846715.jpg  →  11846715-40.jpg\n",
            "41-11846715.jpg  →  11846715-41.jpg\n",
            "42-11846715.jpg  →  11846715-42.jpg\n",
            "43-11846715.jpg  →  11846715-43.jpg\n",
            "44-11846715.jpg  →  11846715-44.jpg\n",
            "45-11846715.jpg  →  11846715-45.jpg\n",
            "46-11846715.jpg  →  11846715-46.jpg\n",
            "47-11846715.jpg  →  11846715-47.jpg\n",
            "48-11846715.jpg  →  11846715-48.jpg\n",
            "49-11846715.jpg  →  11846715-49.jpg\n",
            "50-11846715.jpg  →  11846715-50.jpg\n",
            "51-11846715.jpg  →  11846715-51.jpg\n",
            "52-11846715.jpg  →  11846715-52.jpg\n",
            "53-11846715.jpg  →  11846715-53.jpg\n",
            "54-11846715.jpg  →  11846715-54.jpg\n",
            "55-11846715.jpg  →  11846715-55.jpg\n",
            "56-11846715.jpg  →  11846715-56.jpg\n",
            "57-11846715.jpg  →  11846715-57.jpg\n",
            "58-11846715.jpg  →  11846715-58.jpg\n",
            "59-11846715.jpg  →  11846715-59.jpg\n",
            "60-11846715.jpg  →  11846715-60.jpg\n",
            "61-11846715.jpg  →  11846715-61.jpg\n",
            "62-11846715.jpg  →  11846715-62.jpg\n",
            "63-11846715.jpg  →  11846715-63.jpg\n",
            "64-11846715.jpg  →  11846715-64.jpg\n",
            "65-11846715.jpg  →  11846715-65.jpg\n",
            "66-11846715.jpg  →  11846715-66.jpg\n",
            "101-11846715.jpg  →  11846715-101.jpg\n",
            "102-11846715.jpg  →  11846715-102.jpg\n",
            "103-11846715.jpg  →  11846715-103.jpg\n",
            "104-11846715.jpg  →  11846715-104.jpg\n",
            "105-11846715.jpg  →  11846715-105.jpg\n",
            "1-1139339.jpg  →  1139339-1.jpg\n",
            "3-1139339.jpg  →  1139339-3.jpg\n",
            "2-1139339.jpg  →  1139339-2.jpg\n",
            "4-1139339.jpg  →  1139339-4.jpg\n",
            "5-1139339.jpg  →  1139339-5.jpg\n",
            "6-1139339.jpg  →  1139339-6.jpg\n",
            "7-1139339.jpg  →  1139339-7.jpg\n",
            "8-1139339.jpg  →  1139339-8.jpg\n",
            "9-1139339.jpg  →  1139339-9.jpg\n",
            "10-1139339.jpg  →  1139339-10.jpg\n",
            "11-1139339.jpg  →  1139339-11.jpg\n",
            "12-1139339.jpg  →  1139339-12.jpg\n",
            "13-1139339.jpg  →  1139339-13.jpg\n",
            "14-1139339.jpg  →  1139339-14.jpg\n",
            "15-1139339.jpg  →  1139339-15.jpg\n",
            "16-1139339.jpg  →  1139339-16.jpg\n",
            "17-1139339.jpg  →  1139339-17.jpg\n",
            "18-1139339.jpg  →  1139339-18.jpg\n",
            "19-1139339.jpg  →  1139339-19.jpg\n",
            "20-1139339.jpg  →  1139339-20.jpg\n",
            "21-1139339.jpg  →  1139339-21.jpg\n",
            "22-1139339.jpg  →  1139339-22.jpg\n",
            "23-1139339.jpg  →  1139339-23.jpg\n",
            "24-1139339.jpg  →  1139339-24.jpg\n",
            "25-1139339.jpg  →  1139339-25.jpg\n",
            "26-1139339.jpg  →  1139339-26.jpg\n",
            "27-1139339.jpg  →  1139339-27.jpg\n",
            "28-1139339.jpg  →  1139339-28.jpg\n",
            "29-1139339.jpg  →  1139339-29.jpg\n",
            "30-1139339.jpg  →  1139339-30.jpg\n",
            "31-1139339.jpg  →  1139339-31.jpg\n",
            "32-1139339.jpg  →  1139339-32.jpg\n",
            "33-1139339.jpg  →  1139339-33.jpg\n",
            "34-1139339.jpg  →  1139339-34.jpg\n",
            "1-10794878.tif  →  10794878-1.tif\n",
            "2-10794878.jpg  →  10794878-2.jpg\n",
            "3-10794878.tif  →  10794878-3.tif\n",
            "4-10794878.tif  →  10794878-4.tif\n",
            "5-10794878.tif  →  10794878-5.tif\n",
            "6-10794878.tif  →  10794878-6.tif\n",
            "7-10794878.tif  →  10794878-7.tif\n",
            "8-10794878.tif  →  10794878-8.tif\n",
            "9-10794878.tif  →  10794878-9.tif\n",
            "10-10794878.tif  →  10794878-10.tif\n",
            "11-10794878.tif  →  10794878-11.tif\n",
            "12-10794878.tif  →  10794878-12.tif\n",
            "13-10794878.tif  →  10794878-13.tif\n",
            "14-10794878.tif  →  10794878-14.tif\n",
            "15-10794878.tif  →  10794878-15.tif\n",
            "16-10794878.tif  →  10794878-16.tif\n",
            "17-10794878.tif  →  10794878-17.tif\n",
            "18-10794878.tif  →  10794878-18.tif\n",
            "19-10794878.tif  →  10794878-19.tif\n",
            "20-10794878.tif  →  10794878-20.tif\n",
            "21-10794878.tif  →  10794878-21.tif\n",
            "1-10385045R.tif  →  10385045R-1.tif\n",
            "2-10385045R.tif  →  10385045R-2.tif\n",
            "3-10385045R.tif  →  10385045R-3.tif\n",
            "4-10385045R.tif  →  10385045R-4.tif\n",
            "5-10385045R.tif  →  10385045R-5.tif\n",
            "6-10385045R.tif  →  10385045R-6.tif\n",
            "7-10385045R.tif  →  10385045R-7.tif\n",
            "8-10385045R.tif  →  10385045R-8.tif\n",
            "9-10385045R.tif  →  10385045R-9.tif\n",
            "10-10385045R.tif  →  10385045R-10.tif\n",
            "11-10385045R.tif  →  10385045R-11.tif\n",
            "12-10385045R.tif  →  10385045R-12.tif\n",
            "13-10385045R.tif  →  10385045R-13.tif\n",
            "14-10385045R.tif  →  10385045R-14.tif\n",
            "15-10385045R.tif  →  10385045R-15.tif\n",
            "16-10385045R.tif  →  10385045R-16.tif\n",
            "17-10385045R.tif  →  10385045R-17.tif\n",
            "18-10385045R.tif  →  10385045R-18.tif\n",
            "19-10385045R.tif  →  10385045R-19.tif\n",
            "20-10385045R.tif  →  10385045R-20.tif\n",
            "1-10385045L.tif  →  10385045L-1.tif\n",
            "1-10385045.tif  →  10385045-1.tif\n",
            "2-10385045L.tif  →  10385045L-2.tif\n",
            "2-10385045.tif  →  10385045-2.tif\n",
            "3-10385045L.tif  →  10385045L-3.tif\n",
            "3-10385045.tif  →  10385045-3.tif\n",
            "4-10385045.tif  →  10385045-4.tif\n",
            "4-10385045L.tif  →  10385045L-4.tif\n",
            "5-10385045L.tif  →  10385045L-5.tif\n",
            "5-10385045.tif  →  10385045-5.tif\n",
            "6-10385045L.tif  →  10385045L-6.tif\n",
            "7-10385045L.tif  →  10385045L-7.tif\n",
            "8-10385045L.tif  →  10385045L-8.tif\n",
            "9-10385045L.tif  →  10385045L-9.tif\n",
            "10-10385045L.tif  →  10385045L-10.tif\n",
            "11-10385045L.tif  →  10385045L-11.tif\n",
            "12-10385045L.tif  →  10385045L-12.tif\n",
            "13-10385045L.tif  →  10385045L-13.tif\n",
            "14-10385045L.tif  →  10385045L-14.tif\n",
            "15-10385045L.tif  →  10385045L-15.tif\n",
            "16-10385045L.tif  →  10385045L-16.tif\n",
            "17-10385045L.tif  →  10385045L-17.tif\n",
            "18-10385045L.tif  →  10385045L-18.tif\n",
            "19-10385045L.tif  →  10385045L-19.tif\n",
            "20-10385045L.tif  →  10385045L-20.tif\n",
            "リネーム完了\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "kEykwoRymCEj",
        "outputId": "65a76989-3522-4f61-90cf-5084357c4904",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# ディレクトリ\n",
        "base_dir = \"/content/drive/MyDrive/nv_detection_project/processed/images_512\"\n",
        "train_dir = \"/content/drive/MyDrive/nv_detection_project/processed/images_512_trainval/train\"\n",
        "val_dir = \"/content/drive/MyDrive/nv_detection_project/processed/images_512_trainval/val\"\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "# ファイル一覧取得\n",
        "file_list = [f for f in os.listdir(base_dir) if f.endswith(\".png\")]\n",
        "\n",
        "# 患者ごとに画像をまとめる\n",
        "pid_dict = defaultdict(list)\n",
        "for fname in file_list:\n",
        "    pid = fname.split(\"-\")[0]\n",
        "    pid_dict[pid].append(fname)\n",
        "\n",
        "total_imgs = len(file_list)\n",
        "target_train = int(total_imgs * 0.8)\n",
        "\n",
        "print(f\"Total images = {total_imgs}\")\n",
        "print(f\"Train target = {target_train}\")\n",
        "\n",
        "# 患者ID＋画像枚数セットをランダムに並べる\n",
        "items = list(pid_dict.items())\n",
        "random.seed(42)\n",
        "random.shuffle(items)\n",
        "\n",
        "train_ids = set()\n",
        "train_count = 0\n",
        "\n",
        "# 患者単位で積み上げていく\n",
        "for pid, imgs in items:\n",
        "    if train_count + len(imgs) <= target_train:\n",
        "        train_ids.add(pid)\n",
        "        train_count += len(imgs)\n",
        "\n",
        "print(f\"Assigned to train = {train_count} images\")\n",
        "print(f\"Train patients = {len(train_ids)}\")\n",
        "\n",
        "# コピー実行\n",
        "for fname in file_list:\n",
        "    pid = fname.split(\"-\")[0]\n",
        "    src = os.path.join(base_dir, fname)\n",
        "    if pid in train_ids:\n",
        "        dst = os.path.join(train_dir, fname)\n",
        "    else:\n",
        "        dst = os.path.join(val_dir, fname)\n",
        "    shutil.copy2(src, dst)\n",
        "\n",
        "print(\"Done! Randomized patient-locked 8:2 split completed.\")\n"
      ],
      "metadata": {
        "id": "7Y0BkZTTpnbL",
        "outputId": "6f123e48-18e8-405e-cb89-89fed203c997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images = 145\n",
            "Train target = 116\n",
            "Assigned to train = 95 images\n",
            "Train patients = 4\n",
            "Done! Randomized patient-locked 8:2 split completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# ====== パス設定 ======\n",
        "# 画像\n",
        "base_dir_img = \"/content/drive/MyDrive/nv_detection_project/processed/images_512\"\n",
        "train_img_dir = \"/content/drive/MyDrive/nv_detection_project/processed/images_512_trainval/train\"\n",
        "val_img_dir   = \"/content/drive/MyDrive/nv_detection_project/processed/images_512_trainval/val\"\n",
        "\n",
        "# マスク\n",
        "base_dir_mask = \"/content/drive/MyDrive/nv_detection_project/processed/masks_512\"\n",
        "train_mask_dir = \"/content/drive/MyDrive/nv_detection_project/processed/masks_512_trainval/train\"\n",
        "val_mask_dir   = \"/content/drive/MyDrive/nv_detection_project/processed/masks_512_trainval/val\"\n",
        "\n",
        "# 出力ディレクトリ作成\n",
        "os.makedirs(train_img_dir, exist_ok=True)\n",
        "os.makedirs(val_img_dir, exist_ok=True)\n",
        "os.makedirs(train_mask_dir, exist_ok=True)\n",
        "os.makedirs(val_mask_dir, exist_ok=True)\n",
        "\n",
        "# ====== 画像ファイル一覧（これを基準に分割） ======\n",
        "img_files = [f for f in os.listdir(base_dir_img) if f.endswith(\".png\")]\n",
        "\n",
        "# 患者ごとに画像をまとめる\n",
        "pid_dict = defaultdict(list)\n",
        "for fname in img_files:\n",
        "    pid = fname.split(\"-\")[0]   # ハイフン前が患者ID\n",
        "    pid_dict[pid].append(fname)\n",
        "\n",
        "total_imgs = len(img_files)\n",
        "target_train = int(total_imgs * 0.8)\n",
        "\n",
        "print(f\"Total images = {total_imgs}\")\n",
        "print(f\"Train target = {target_train}\")\n",
        "\n",
        "# 患者ID＋画像リストをランダムに並べる\n",
        "items = list(pid_dict.items())\n",
        "random.seed(42)   # 再現性\n",
        "random.shuffle(items)\n",
        "\n",
        "train_ids = set()\n",
        "train_count = 0\n",
        "\n",
        "# 患者単位で積み上げて 8割を目指す\n",
        "for pid, imgs in items:\n",
        "    if train_count + len(imgs) <= target_train:\n",
        "        train_ids.add(pid)\n",
        "        train_count += len(imgs)\n",
        "\n",
        "print(f\"Assigned to train = {train_count} images\")\n",
        "print(f\"Train patients    = {len(train_ids)}\")\n",
        "\n",
        "# ====== 画像＆マスクを同じルールでコピー ======\n",
        "missing_masks = []\n",
        "\n",
        "for fname in img_files:\n",
        "    pid = fname.split(\"-\")[0]\n",
        "\n",
        "    # 画像のコピー\n",
        "    src_img = os.path.join(base_dir_img, fname)\n",
        "    if pid in train_ids:\n",
        "        dst_img = os.path.join(train_img_dir, fname)\n",
        "        dst_mask = os.path.join(train_mask_dir, fname)\n",
        "    else:\n",
        "        dst_img = os.path.join(val_img_dir, fname)\n",
        "        dst_mask = os.path.join(val_mask_dir, fname)\n",
        "\n",
        "    shutil.copy2(src_img, dst_img)\n",
        "\n",
        "    # マスクのコピー（ファイル名が同じ想定）\n",
        "    src_mask = os.path.join(base_dir_mask, fname)\n",
        "    if os.path.exists(src_mask):\n",
        "        shutil.copy2(src_mask, dst_mask)\n",
        "    else:\n",
        "        missing_masks.append(fname)\n",
        "\n",
        "print(\"Done! Randomized patient-locked 8:2 split for images & masks.\")\n",
        "\n",
        "if missing_masks:\n",
        "    print(\"⚠ マスクが見つからなかったファイル一覧:\")\n",
        "    for f in missing_masks:\n",
        "        print(\"  \", f)\n"
      ],
      "metadata": {
        "id": "7NhpBOukqKBt",
        "outputId": "8bf0b429-f396-4d61-e90d-c790cb49adda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images = 145\n",
            "Train target = 116\n",
            "Assigned to train = 95 images\n",
            "Train patients    = 4\n",
            "Done! Randomized patient-locked 8:2 split for images & masks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "ZYBEWWYguJ3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OCTDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, augment=False,\n",
        "                 ensure_size=None):\n",
        "        \"\"\"\n",
        "        image_dir: 画像フォルダ（train か val）\n",
        "        mask_dir : マスクフォルダ（train か val）\n",
        "        augment  : Data Augmentation を使うかどうか\n",
        "        ensure_size: (W, H) のタプル。例 (512, 512)\n",
        "                     None の場合はリサイズしない\n",
        "        \"\"\"\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.augment = augment\n",
        "        self.ensure_size = ensure_size\n",
        "\n",
        "        # 画像ファイル一覧（マスクも同名で存在すると仮定）\n",
        "        self.image_files = sorted([\n",
        "            f for f in os.listdir(image_dir)\n",
        "            if f.endswith(\".png\")\n",
        "        ])\n",
        "\n",
        "        # Tensor 変換（[0,255] → [0,1] & (C,H,W)）\n",
        "        self.to_tensor = T.ToTensor()\n",
        "\n",
        "        # ColorJitter（輝度・コントラスト；画像のみ）\n",
        "        self.color_jitter = T.ColorJitter(\n",
        "            brightness=0.2,\n",
        "            contrast=0.2\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "\n",
        "        # パス作成\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        mask_path = os.path.join(self.mask_dir, img_name)\n",
        "\n",
        "        # グレースケールで読み込み（1ch）\n",
        "        image = Image.open(img_path).convert(\"L\")\n",
        "        mask  = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        # 必要ならサイズを強制（例：512×512）\n",
        "        if self.ensure_size is not None:\n",
        "            w, h = self.ensure_size  # (W, H)\n",
        "            image = image.resize((w, h), resample=Image.BILINEAR)\n",
        "            mask  = mask.resize((w, h), resample=Image.NEAREST)\n",
        "\n",
        "        # ---------- Data Augmentation ----------\n",
        "        if self.augment:\n",
        "            # 1) 左右反転（RandomHorizontalFlip 相当）\n",
        "            if random.random() < 0.5:\n",
        "                image = TF.hflip(image)\n",
        "                mask  = TF.hflip(mask)\n",
        "\n",
        "            # 2) 回転（RandomRotation ±10度 相当）\n",
        "            angle = random.uniform(-10, 10)\n",
        "            # ここは PIL の rotate を使う（バージョン依存しないので安全）\n",
        "            image = image.rotate(angle, resample=Image.BILINEAR)\n",
        "            mask  = mask.rotate(angle,  resample=Image.NEAREST)\n",
        "\n",
        "            # 3) ColorJitter（画像のみ）\n",
        "            image = self.color_jitter(image)\n",
        "\n",
        "        # ---------- Tensor 化（[0,1], (C,H,W)） ----------\n",
        "        image = self.to_tensor(image)  # (1, H, W)\n",
        "        mask  = self.to_tensor(mask)   # (1, H, W)\n",
        "\n",
        "        # マスクを 0/1 に揃える（補間の影響を消す）\n",
        "        mask = (mask > 0.5).float()\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "nKVSH6POuOFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === パス ===\n",
        "base_path = \"/content/drive/MyDrive/nv_detection_project/processed\"\n",
        "\n",
        "train_img_dir  = os.path.join(base_path, \"images_512_trainval\", \"train\")\n",
        "train_mask_dir = os.path.join(base_path, \"masks_512_trainval\", \"train\")\n",
        "\n",
        "val_img_dir  = os.path.join(base_path, \"images_512_trainval\", \"val\")\n",
        "val_mask_dir = os.path.join(base_path, \"masks_512_trainval\", \"val\")\n",
        "\n",
        "# === Dataset 作成 ===\n",
        "# 512×512 に揃える場合は ensure_size=(512,512)\n",
        "train_dataset = OCTDataset(\n",
        "    train_img_dir,\n",
        "    train_mask_dir,\n",
        "    augment=True,\n",
        "    ensure_size=(512, 512)   # 512×512 前提の場合\n",
        ")\n",
        "\n",
        "val_dataset = OCTDataset(\n",
        "    val_img_dir,\n",
        "    val_mask_dir,\n",
        "    augment=False,            # val では基本 augmentation しない\n",
        "    ensure_size=(512, 512)\n",
        ")\n",
        "\n",
        "# === DataLoader 作成 ===\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "WL3D2oQJuV0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[10]"
      ],
      "metadata": {
        "id": "LZ-J6sApvo_f",
        "outputId": "5a9607b6-62ca-4d3b-ee4b-70487f8935d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
              " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "BXbPlqVZwBkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"Conv2d → BN → ReLU を2回（U-Netの基本ブロック）\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"MaxPool でダウンサンプル → DoubleConv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"アップサンプル（ConvTranspose2d）→ skip connection と concat → DoubleConv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        # in_channels は upsample 前のチャネル数\n",
        "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "        # concat 後のチャネル数 = out_channels (from up) + skip_channels\n",
        "        self.conv = DoubleConv(in_channels, out_channels)  # in_channels = out_channels + skip_channels\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        \"\"\"\n",
        "        x1: decoder側の特徴（小さいやつ）\n",
        "        x2: encoder側のskip接続（大きいサイズ）\n",
        "        \"\"\"\n",
        "        x1 = self.up(x1)  # アップサンプル\n",
        "\n",
        "        # 形が合わない場合の調整（今回512→256→...→32なので基本ズレない）\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        if diffY != 0 or diffX != 0:\n",
        "            x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                            diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "        # skip connection: チャネル方向に結合\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    \"\"\"最後の1x1 conv でチャネル1に落とす（logits出力）\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n"
      ],
      "metadata": {
        "id": "lEAUkI9Swpzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=1, n_classes=1):\n",
        "        super().__init__()\n",
        "        self.inc   = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024)\n",
        "\n",
        "        self.up1 = Up(1024, 512)\n",
        "        self.up2 = Up(512, 256)\n",
        "        self.up3 = Up(256, 128)\n",
        "        self.up4 = Up(128, 64)\n",
        "\n",
        "        self.outc = OutConv(64, n_classes)  # n_classes=1 → 1chのlogits\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x1 = self.inc(x)      # (N, 64, 512, 512)\n",
        "        x2 = self.down1(x1)   # (N, 128, 256, 256)\n",
        "        x3 = self.down2(x2)   # (N, 256, 128, 128)\n",
        "        x4 = self.down3(x3)   # (N, 512, 64, 64)\n",
        "        x5 = self.down4(x4)   # (N, 1024, 32, 32)\n",
        "\n",
        "        # Decoder + skip\n",
        "        x = self.up1(x5, x4)  # (N, 512, 64, 64)\n",
        "        x = self.up2(x,  x3)  # (N, 256, 128, 128)\n",
        "        x = self.up3(x,  x2)  # (N, 128, 256, 256)\n",
        "        x = self.up4(x,  x1)  # (N, 64,  512, 512)\n",
        "\n",
        "        logits = self.outc(x)  # (N, 1, 512, 512)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "Y8QbrTJswq4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        \"\"\"\n",
        "        logits: (N, 1, H, W)  シグモイド前\n",
        "        targets: (N, 1, H, W) 0 or 1\n",
        "        \"\"\"\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        # flatten\n",
        "        probs_flat   = probs.contiguous().view(probs.shape[0], -1)\n",
        "        targets_flat = targets.contiguous().view(targets.shape[0], -1)\n",
        "\n",
        "        intersection = (probs_flat * targets_flat).sum(dim=1)\n",
        "        union = probs_flat.sum(dim=1) + targets_flat.sum(dim=1)\n",
        "\n",
        "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
        "\n",
        "        # バッチ平均のDice Loss\n",
        "        return 1. - dice.mean()\n"
      ],
      "metadata": {
        "id": "J0SvHqdqxlX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BCEDiceLoss(nn.Module):\n",
        "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
        "        super().__init__()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.dice = DiceLoss()\n",
        "        self.bce_weight = bce_weight\n",
        "        self.dice_weight = dice_weight\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        loss_bce  = self.bce(logits, targets)\n",
        "        loss_dice = self.dice(logits, targets)\n",
        "        loss = self.bce_weight * loss_bce + self.dice_weight * loss_dice\n",
        "        return loss, loss_bce, loss_dice\n"
      ],
      "metadata": {
        "id": "3ntTbVRpwoUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = UNet(n_channels=1, n_classes=1).to(device)\n",
        "criterion = BCEDiceLoss(bce_weight=0.5, dice_weight=0.5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# 1イテレーションだけ例\n",
        "model.train()\n",
        "for images, masks in train_loader:\n",
        "    images = images.to(device)           # (N, 1, 512, 512)\n",
        "    masks  = masks.to(device)           # (N, 1, 512, 512)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits = model(images)              # (N, 1, 512, 512)\n",
        "    loss, loss_bce, loss_dice = criterion(logits, masks)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"loss={loss.item():.4f}, bce={loss_bce.item():.4f}, dice_loss={loss_dice.item():.4f}\")\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwm0TBkoxqBT",
        "outputId": "03bd9ec9-7f40-4548-b8fd-59c61939c618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss=0.5520, bce=0.6854, dice_loss=0.4186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# ===== すでにある部分 =====\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = UNet(n_channels=1, n_classes=1).to(device)\n",
        "criterion = BCEDiceLoss(bce_weight=0.5, dice_weight=0.5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# ===== Dice係数を計算する関数（メトリクス用） =====\n",
        "def dice_coef(preds, targets, eps=1e-7):\n",
        "    \"\"\"\n",
        "    preds: (N, 1, H, W) after sigmoid & threshold\n",
        "    targets: (N, 1, H, W)\n",
        "    \"\"\"\n",
        "    preds = preds.view(preds.size(0), -1)\n",
        "    targets = targets.view(targets.size(0), -1)\n",
        "\n",
        "    intersection = (preds * targets).sum(dim=1)\n",
        "    union = preds.sum(dim=1) + targets.sum(dim=1)\n",
        "\n",
        "    dice = (2.0 * intersection + eps) / (union + eps)\n",
        "    return dice.mean()\n",
        "\n",
        "# ===== 学習ループ (Step 8) =====\n",
        "num_epochs = 80  # 目安: 50〜100\n",
        "best_val_loss = np.inf\n",
        "save_path = \"/content/drive/MyDrive/nv_detection_project/models\"\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # --------------------\n",
        "    # Train\n",
        "    # --------------------\n",
        "    model.train()\n",
        "    train_loss_sum = 0.0\n",
        "    train_bce_sum = 0.0\n",
        "    train_dice_loss_sum = 0.0\n",
        "    train_dice_metric_sum = 0.0\n",
        "    n_train_batches = 0\n",
        "\n",
        "    for images, masks in train_loader:\n",
        "        images = images.to(device)   # (N, 1, 512, 512)\n",
        "        masks  = masks.to(device)   # (N, 1, 512, 512)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(images)      # (N, 1, 512, 512)\n",
        "        loss, loss_bce, loss_dice = criterion(logits, masks)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # メトリクス用にDice係数を計算（predは0/1）\n",
        "        with torch.no_grad():\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).float()\n",
        "            dice_metric = dice_coef(preds, masks)\n",
        "\n",
        "        train_loss_sum      += loss.item()\n",
        "        train_bce_sum       += loss_bce.item()\n",
        "        train_dice_loss_sum += loss_dice.item()\n",
        "        train_dice_metric_sum += dice_metric.item()\n",
        "        n_train_batches += 1\n",
        "\n",
        "    train_loss      = train_loss_sum / n_train_batches\n",
        "    train_bce       = train_bce_sum / n_train_batches\n",
        "    train_dice_loss = train_dice_loss_sum / n_train_batches\n",
        "    train_dice_metric = train_dice_metric_sum / n_train_batches\n",
        "\n",
        "    # --------------------\n",
        "    # Validation\n",
        "    # --------------------\n",
        "    model.eval()\n",
        "    val_loss_sum = 0.0\n",
        "    val_bce_sum = 0.0\n",
        "    val_dice_loss_sum = 0.0\n",
        "    val_dice_metric_sum = 0.0\n",
        "    n_val_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images = images.to(device)\n",
        "            masks  = masks.to(device)\n",
        "\n",
        "            logits = model(images)\n",
        "            loss, loss_bce, loss_dice = criterion(logits, masks)\n",
        "\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).float()\n",
        "            dice_metric = dice_coef(preds, masks)\n",
        "\n",
        "            val_loss_sum      += loss.item()\n",
        "            val_bce_sum       += loss_bce.item()\n",
        "            val_dice_loss_sum += loss_dice.item()\n",
        "            val_dice_metric_sum += dice_metric.item()\n",
        "            n_val_batches += 1\n",
        "\n",
        "    val_loss      = val_loss_sum / n_val_batches\n",
        "    val_bce       = val_bce_sum / n_val_batches\n",
        "    val_dice_loss = val_dice_loss_sum / n_val_batches\n",
        "    val_dice_metric = val_dice_metric_sum / n_val_batches\n",
        "\n",
        "    # --------------------\n",
        "    # ログ表示\n",
        "    # --------------------\n",
        "    print(f\"[Epoch {epoch:03d}/{num_epochs}] \"\n",
        "          f\"Train: loss={train_loss:.4f} (bce={train_bce:.4f}, dice_loss={train_dice_loss:.4f}, dice={train_dice_metric:.4f}) | \"\n",
        "          f\"Val: loss={val_loss:.4f} (bce={val_bce:.4f}, dice_loss={val_dice_loss:.4f}, dice={val_dice_metric:.4f})\")\n",
        "\n",
        "    # --------------------\n",
        "    # ベストモデルの保存（val_lossが最小）\n",
        "    # --------------------\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"  -> Best model updated! (saved to {save_path})\")\n"
      ],
      "metadata": {
        "id": "unJ-73oB2-3Q",
        "outputId": "bdeadccf-d7da-4de5-8c8c-39e456aa470a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 001/80] Train: loss=0.4105 (bce=0.4934, dice_loss=0.3275, dice=0.7082) | Val: loss=0.3631 (bce=0.4903, dice_loss=0.2359, dice=0.8975)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 002/80] Train: loss=0.2951 (bce=0.3607, dice_loss=0.2295, dice=0.8843) | Val: loss=0.3432 (bce=0.4563, dice_loss=0.2301, dice=0.8428)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 003/80] Train: loss=0.2458 (bce=0.2995, dice_loss=0.1921, dice=0.9100) | Val: loss=0.1417 (bce=0.1870, dice_loss=0.0965, dice=0.9767)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 004/80] Train: loss=0.1961 (bce=0.2369, dice_loss=0.1553, dice=0.9449) | Val: loss=0.1705 (bce=0.2346, dice_loss=0.1064, dice=0.9617)\n",
            "[Epoch 005/80] Train: loss=0.1951 (bce=0.2381, dice_loss=0.1522, dice=0.9395) | Val: loss=0.1252 (bce=0.1659, dice_loss=0.0846, dice=0.9806)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 006/80] Train: loss=0.1834 (bce=0.2234, dice_loss=0.1434, dice=0.9404) | Val: loss=0.1369 (bce=0.1851, dice_loss=0.0887, dice=0.9742)\n",
            "[Epoch 007/80] Train: loss=0.1837 (bce=0.2282, dice_loss=0.1391, dice=0.9371) | Val: loss=0.1405 (bce=0.1973, dice_loss=0.0838, dice=0.9678)\n",
            "[Epoch 008/80] Train: loss=0.1725 (bce=0.2150, dice_loss=0.1301, dice=0.9425) | Val: loss=0.1014 (bce=0.1383, dice_loss=0.0645, dice=0.9806)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 009/80] Train: loss=0.1632 (bce=0.2028, dice_loss=0.1236, dice=0.9500) | Val: loss=0.1408 (bce=0.2010, dice_loss=0.0807, dice=0.9622)\n",
            "[Epoch 010/80] Train: loss=0.1404 (bce=0.1743, dice_loss=0.1065, dice=0.9602) | Val: loss=0.1188 (bce=0.1635, dice_loss=0.0740, dice=0.9735)\n",
            "[Epoch 011/80] Train: loss=0.1242 (bce=0.1518, dice_loss=0.0965, dice=0.9673) | Val: loss=0.1424 (bce=0.2039, dice_loss=0.0809, dice=0.9626)\n",
            "[Epoch 012/80] Train: loss=0.1121 (bce=0.1373, dice_loss=0.0869, dice=0.9731) | Val: loss=0.1560 (bce=0.2265, dice_loss=0.0854, dice=0.9558)\n",
            "[Epoch 013/80] Train: loss=0.1012 (bce=0.1231, dice_loss=0.0793, dice=0.9771) | Val: loss=0.0814 (bce=0.1067, dice_loss=0.0560, dice=0.9911)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 014/80] Train: loss=0.1046 (bce=0.1295, dice_loss=0.0796, dice=0.9741) | Val: loss=0.0763 (bce=0.1004, dice_loss=0.0522, dice=0.9906)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 015/80] Train: loss=0.0959 (bce=0.1182, dice_loss=0.0737, dice=0.9768) | Val: loss=0.0733 (bce=0.0965, dice_loss=0.0501, dice=0.9925)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 016/80] Train: loss=0.0933 (bce=0.1159, dice_loss=0.0706, dice=0.9766) | Val: loss=0.0645 (bce=0.0843, dice_loss=0.0447, dice=0.9937)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 017/80] Train: loss=0.0864 (bce=0.1075, dice_loss=0.0653, dice=0.9795) | Val: loss=0.1110 (bce=0.1558, dice_loss=0.0662, dice=0.9661)\n",
            "[Epoch 018/80] Train: loss=0.0859 (bce=0.1079, dice_loss=0.0638, dice=0.9782) | Val: loss=0.0616 (bce=0.0817, dice_loss=0.0416, dice=0.9930)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 019/80] Train: loss=0.0829 (bce=0.1041, dice_loss=0.0618, dice=0.9781) | Val: loss=0.0626 (bce=0.0833, dice_loss=0.0419, dice=0.9921)\n",
            "[Epoch 020/80] Train: loss=0.0794 (bce=0.1005, dice_loss=0.0583, dice=0.9795) | Val: loss=0.0612 (bce=0.0815, dice_loss=0.0408, dice=0.9914)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 021/80] Train: loss=0.0754 (bce=0.0949, dice_loss=0.0559, dice=0.9805) | Val: loss=0.0473 (bce=0.0629, dice_loss=0.0317, dice=0.9950)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 022/80] Train: loss=0.0731 (bce=0.0928, dice_loss=0.0533, dice=0.9824) | Val: loss=0.0488 (bce=0.0649, dice_loss=0.0327, dice=0.9952)\n",
            "[Epoch 023/80] Train: loss=0.0709 (bce=0.0901, dice_loss=0.0517, dice=0.9816) | Val: loss=0.0446 (bce=0.0590, dice_loss=0.0303, dice=0.9958)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 024/80] Train: loss=0.0722 (bce=0.0925, dice_loss=0.0518, dice=0.9797) | Val: loss=0.0445 (bce=0.0593, dice_loss=0.0297, dice=0.9941)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 025/80] Train: loss=0.0779 (bce=0.1017, dice_loss=0.0541, dice=0.9766) | Val: loss=0.0387 (bce=0.0533, dice_loss=0.0241, dice=0.9951)\n",
            "  -> Best model updated! (saved to best_model.pth)\n",
            "[Epoch 026/80] Train: loss=0.0722 (bce=0.0943, dice_loss=0.0502, dice=0.9796) | Val: loss=0.0451 (bce=0.0608, dice_loss=0.0293, dice=0.9951)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}